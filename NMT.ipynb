{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nzx0p0EZj7dX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy\n",
    "import ten\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Input, TimeDistributed, Embedding, GRU, Bidirectional, Dropout, RepeatVector\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dNv7Oexwmmcs"
   },
   "outputs": [],
   "source": [
    "english_file_path = os.path.join('/content/small_vocab_en.txt')\n",
    "french_file_path = os.path.join('/content/small_vocab_fr.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZqsRZaghnhZe"
   },
   "outputs": [],
   "source": [
    "with open(english_file_path, 'r') as f:\n",
    "  english_sentences = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MnD0Y2YXvOBa"
   },
   "outputs": [],
   "source": [
    "with open(french_file_path, 'r') as f:\n",
    "  french_sentences = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "A6akpUC_nLFs"
   },
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "  def lowercasing(self, text):\n",
    "    for i in range(len(text)):\n",
    "      text[i] = text[i].lower()\n",
    "    return text\n",
    "\n",
    "  def tokenization(self, lowercased_text):\n",
    "    tokenizer = Tokenizer(split=' ', char_level=False)\n",
    "    tokenizer.fit_on_texts(lowercased_text)\n",
    "    tokenized_text = tokenizer.texts_to_sequences(lowercased_text)\n",
    "    return tokenized_text, tokenizer\n",
    "\n",
    "  def padding(self, tokenized_text):\n",
    "    max_length = max([len(sent) for sent in tokenized_text])\n",
    "    padded_text = pad_sequences(tokenized_text, maxlen=max_length, padding='post', truncating='post')\n",
    "    return padded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9Uk1IoUsNJR",
    "outputId": "ab930385-2099-426a-b9b1-76f887fc2526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17 23  1  8 67  4 39  7  3  1 55  2 44  0  0]\n",
      " [ 5 20 21  1  9 62  4 43  7  3  1  9 51  2 45]\n",
      " [22  1  9 67  4 38  7  3  1  9 68  2 34  0  0]\n",
      " [ 5 20 21  1  8 64  4 34  7  3  1 57  2 42  0]\n",
      " [29 12 16 13  1  5 82  6 30 12 16  1  5 83  0]]\n"
     ]
    }
   ],
   "source": [
    "#English Text\n",
    "\n",
    "preprocessing = Preprocessing()\n",
    "english_lowercase = preprocessing.lowercasing(english_sentences)\n",
    "english_tokenized_text, english_tokenizer = preprocessing.tokenization(english_lowercase)\n",
    "english_padded_text = preprocessing.padding(english_tokenized_text)\n",
    "\n",
    "print(english_padded_text[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QgDsjLa9s7qI",
    "outputId": "0dbf3671-5c61-4acc-d63f-01881d768e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34  33   1   8  67  37  11  24   6   3   1 112   2  52   0   0   0   0\n",
      "    0   0   0]\n",
      " [  4  30  29   1  12  19   2  55   6   3  95  69   2  44   0   0   0   0\n",
      "    0   0   0]\n",
      " [101   1  12  67   2  48   6   3   1  12  20   2  43   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  4  30  29   1   8 263   2  43   6   3 103  19   2  51   0   0   0   0\n",
      "    0   0   0]\n",
      " [ 39  13  15  16   1  10  90   5  40  13  15   1   7  89   0   0   0   0\n",
      "    0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#French Text Preprocessing\n",
    "\n",
    "french_tokenized_text, french_tokenizer = preprocessing.tokenization(french_sentences)\n",
    "french_padded_text = preprocessing.padding(french_tokenized_text)\n",
    "\n",
    "print(french_padded_text[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUk0rlkmw1Eo",
    "outputId": "68ee0ff4-7483-4bd5-f774-bc13dc00a4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 340\n"
     ]
    }
   ],
   "source": [
    "max_english_sequence_length = english_padded_text.shape[1]\n",
    "max_french_sequence_length = french_padded_text.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9hrwh2jUwzmE"
   },
   "outputs": [],
   "source": [
    "english_padded_text = pad_sequences(english_padded_text[:french_padded_text.shape[0]], max_french_sequence_length)\n",
    "padded_fre = pad_sequences(french_padded_text[:french_padded_text.shape[0]], max_french_sequence_length)\n",
    "tmp_x = padded_fre.reshape((-1, french_padded_text.shape[-2], max_french_sequence_length)) #Reshaping into (Batch size, timesteps, sequence length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jUMmhWuC8Cfo"
   },
   "outputs": [],
   "source": [
    "#tmp_x_encoded = to_categorical(y=tmp_x[0], num_classes=(french_vocab_size+1)) #One hot encoding\n",
    "#french_padded_text_encoded = to_categorical(y=french_padded_text, num_classes=(french_vocab_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CtGphZh90XeL"
   },
   "outputs": [],
   "source": [
    "#batch_size, sequence_length, max_length = tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JoTH4ilVBVrW"
   },
   "outputs": [],
   "source": [
    "#french_padded_text = numpy.reshape(french_padded_text, (batch_size, sequence_length, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DavT89HFkubx",
    "outputId": "2b0784a0-1f56-4cc7-c50e-094c3b3902ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99772, 21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_padded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1iku56wk1qH",
    "outputId": "3b6b12b2-fca4-466f-996d-2e8e5ef87e2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99772, 21)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_fre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVNYAIfD9vlh",
    "outputId": "846ebf14-7817-40a4-bb22-f00ec18909b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 99772, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0Yi1Bwu8mS_",
    "outputId": "129c8f66-e405-4b7b-9550-9aeffdaff802"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99772, 21)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_padded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3P7SYUaD_WYU"
   },
   "outputs": [],
   "source": [
    "#RNN with Embedding\n",
    "\n",
    "rnn_embed_model = Sequential()\n",
    "rnn_embed_model.add(Input(shape=(tmp_x.shape[0]), name='Input Layer'))\n",
    "rnn_embed_model.add(Embedding(input_dim=french_vocab_size+1, output_dim=512, input_length=max_french_sequence_length))\n",
    "rnn_embed_model.add(GRU(units=64, return_sequences=True))\n",
    "rnn_embed_model.add(GRU(units=32, return_sequences=True))\n",
    "rnn_embed_model.add(GRU(units=32, return_sequences=True))\n",
    "rnn_embed_model.add(TimeDistributed(Dense(units=english_vocab_size+1, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7E_4Hh-kAG4o",
    "outputId": "c602a947-7a6c-4a94-86fc-410b6345e733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 1, 512)            174592    \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 1, 64)             110976    \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 1, 32)             9408      \n",
      "                                                                 \n",
      " gru_8 (GRU)                 (None, 1, 32)             6336      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 1, 200)            6600      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307912 (1.17 MB)\n",
      "Trainable params: 307912 (1.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "2495/2495 [==============================] - 37s 13ms/step - loss: 1.4099 - Accuracy: 0.6699 - val_loss: 0.6376 - val_Accuracy: 0.7834\n",
      "Epoch 2/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.5438 - Accuracy: 0.8088 - val_loss: 0.4452 - val_Accuracy: 0.8468\n",
      "Epoch 3/15\n",
      "2495/2495 [==============================] - 27s 11ms/step - loss: 0.3841 - Accuracy: 0.8705 - val_loss: 0.3652 - val_Accuracy: 0.8762\n",
      "Epoch 4/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.3104 - Accuracy: 0.8953 - val_loss: 0.2721 - val_Accuracy: 0.9061\n",
      "Epoch 5/15\n",
      "2495/2495 [==============================] - 26s 11ms/step - loss: 0.2460 - Accuracy: 0.9125 - val_loss: 0.2296 - val_Accuracy: 0.9138\n",
      "Epoch 6/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.2140 - Accuracy: 0.9204 - val_loss: 0.1912 - val_Accuracy: 0.9282\n",
      "Epoch 7/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.1725 - Accuracy: 0.9345 - val_loss: 0.1446 - val_Accuracy: 0.9451\n",
      "Epoch 8/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.1292 - Accuracy: 0.9489 - val_loss: 0.1068 - val_Accuracy: 0.9560\n",
      "Epoch 9/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.1041 - Accuracy: 0.9582 - val_loss: 0.0949 - val_Accuracy: 0.9629\n",
      "Epoch 10/15\n",
      "2495/2495 [==============================] - 28s 11ms/step - loss: 0.0774 - Accuracy: 0.9690 - val_loss: 0.0624 - val_Accuracy: 0.9743\n",
      "Epoch 11/15\n",
      "2495/2495 [==============================] - 29s 12ms/step - loss: 0.0655 - Accuracy: 0.9740 - val_loss: 0.0581 - val_Accuracy: 0.9760\n",
      "Epoch 12/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.0506 - Accuracy: 0.9778 - val_loss: 0.0504 - val_Accuracy: 0.9782\n",
      "Epoch 13/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.0498 - Accuracy: 0.9784 - val_loss: 0.0437 - val_Accuracy: 0.9800\n",
      "Epoch 14/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.0470 - Accuracy: 0.9794 - val_loss: 0.0414 - val_Accuracy: 0.9807\n",
      "Epoch 15/15\n",
      "2495/2495 [==============================] - 26s 10ms/step - loss: 0.0400 - Accuracy: 0.9811 - val_loss: 0.0378 - val_Accuracy: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d29718c9bd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_embed_model.summary()\n",
    "\n",
    "rnn_embed_model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['Accuracy'])\n",
    "\n",
    "rnn_embed_model.fit(tmp_x[0], english_padded_text, verbose=1, batch_size=32, epochs=15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sSg6dg2M_XAb"
   },
   "outputs": [],
   "source": [
    "#Bidirectional RNN\n",
    "\n",
    "bi_rnn_model = Sequential()\n",
    "bi_rnn_model.add(Input(shape=(tmp_x.shape[0]), name='Input Layer'))\n",
    "bi_rnn_model.add(Embedding(input_dim=french_vocab_size+1, output_dim=128, input_length=max_french_sequence_length))\n",
    "bi_rnn_model.add(Bidirectional(layer=LSTM(32, return_sequences=True)))\n",
    "bi_rnn_model.add(TimeDistributed(Dense(units=english_vocab_size+1, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HlpWPA8WCjEc",
    "outputId": "d0c24a9b-293e-45b0-8edf-2a0c218ef34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 1, 128)            43648     \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 1, 64)             41216     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, 1, 200)            13000     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97864 (382.28 KB)\n",
      "Trainable params: 97864 (382.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "2495/2495 [==============================] - 30s 11ms/step - loss: 1.3069 - Accuracy: 0.6857 - val_loss: 0.6912 - val_Accuracy: 0.7922\n",
      "Epoch 2/15\n",
      "2495/2495 [==============================] - 22s 9ms/step - loss: 0.5534 - Accuracy: 0.8335 - val_loss: 0.4557 - val_Accuracy: 0.8585\n",
      "Epoch 3/15\n",
      "2495/2495 [==============================] - 22s 9ms/step - loss: 0.4060 - Accuracy: 0.8702 - val_loss: 0.3633 - val_Accuracy: 0.8819\n",
      "Epoch 4/15\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 0.3229 - Accuracy: 0.8943 - val_loss: 0.2862 - val_Accuracy: 0.9061\n",
      "Epoch 5/15\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 0.2643 - Accuracy: 0.9132 - val_loss: 0.2386 - val_Accuracy: 0.9224\n",
      "Epoch 6/15\n",
      "2495/2495 [==============================] - 24s 9ms/step - loss: 0.2140 - Accuracy: 0.9305 - val_loss: 0.1923 - val_Accuracy: 0.9376\n",
      "Epoch 7/15\n",
      "2495/2495 [==============================] - 22s 9ms/step - loss: 0.1815 - Accuracy: 0.9419 - val_loss: 0.1611 - val_Accuracy: 0.9491\n",
      "Epoch 8/15\n",
      "2495/2495 [==============================] - 21s 9ms/step - loss: 0.1503 - Accuracy: 0.9523 - val_loss: 0.1373 - val_Accuracy: 0.9561\n",
      "Epoch 9/15\n",
      "2495/2495 [==============================] - 22s 9ms/step - loss: 0.1292 - Accuracy: 0.9593 - val_loss: 0.1141 - val_Accuracy: 0.9633\n",
      "Epoch 10/15\n",
      "2495/2495 [==============================] - 22s 9ms/step - loss: 0.1063 - Accuracy: 0.9656 - val_loss: 0.1030 - val_Accuracy: 0.9671\n",
      "Epoch 11/15\n",
      "2495/2495 [==============================] - 24s 10ms/step - loss: 0.0902 - Accuracy: 0.9699 - val_loss: 0.0866 - val_Accuracy: 0.9709\n",
      "Epoch 12/15\n",
      "2495/2495 [==============================] - 24s 10ms/step - loss: 0.0905 - Accuracy: 0.9699 - val_loss: 0.0822 - val_Accuracy: 0.9716\n",
      "Epoch 13/15\n",
      "2495/2495 [==============================] - 25s 10ms/step - loss: 0.0718 - Accuracy: 0.9748 - val_loss: 0.0690 - val_Accuracy: 0.9754\n",
      "Epoch 14/15\n",
      "2495/2495 [==============================] - 28s 11ms/step - loss: 0.0730 - Accuracy: 0.9742 - val_loss: 0.0662 - val_Accuracy: 0.9756\n",
      "Epoch 15/15\n",
      "2495/2495 [==============================] - 25s 10ms/step - loss: 0.0669 - Accuracy: 0.9757 - val_loss: 0.0616 - val_Accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d296828f190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_rnn_model.summary()\n",
    "\n",
    "bi_rnn_model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['Accuracy'])\n",
    "\n",
    "bi_rnn_model.fit(tmp_x[0], english_padded_text, verbose=1, batch_size=32, epochs=15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "WD0EFbETv1zV"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Encoder\n",
    "model.add(Input(shape=(tmp_x.shape[0]), name='Input Layer'))\n",
    "model.add(Embedding(input_dim=french_vocab_size+1, output_dim=512, input_length=max_french_sequence_length))\n",
    "model.add(LSTM(units=256, return_sequences=True))\n",
    "model.add(Bidirectional(layer=LSTM(128, return_sequences=False)))\n",
    "\n",
    "#context vector\n",
    "model.add(RepeatVector(n=max_french_sequence_length))\n",
    "\n",
    "#Decoder\n",
    "model.add(LSTM(units=256, return_sequences=True))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "#model.add(LSTM(units=16, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(units=english_vocab_size+1, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iP8bX7jkyRMp",
    "outputId": "9f15153f-8803-40ff-856f-e82e614d3961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 1, 512)            174592    \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 1, 256)            787456    \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirecti  (None, 256)               394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " repeat_vector_3 (RepeatVec  (None, 21, 256)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 21, 256)           525312    \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 21, 128)           197120    \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDi  (None, 21, 200)           25800     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2104520 (8.03 MB)\n",
      "Trainable params: 2104520 (8.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "2495/2495 [==============================] - 61s 22ms/step - loss: 1.2184 - Accuracy: 0.6790 - val_loss: 0.6870 - val_Accuracy: 0.7607\n",
      "Epoch 2/25\n",
      "2495/2495 [==============================] - 38s 15ms/step - loss: 0.6186 - Accuracy: 0.7736 - val_loss: 0.5684 - val_Accuracy: 0.7871\n",
      "Epoch 3/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.5680 - Accuracy: 0.7898 - val_loss: 0.5390 - val_Accuracy: 0.7938\n",
      "Epoch 4/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.5120 - Accuracy: 0.8125 - val_loss: 0.4868 - val_Accuracy: 0.8294\n",
      "Epoch 5/25\n",
      "2495/2495 [==============================] - 41s 16ms/step - loss: 0.4557 - Accuracy: 0.8366 - val_loss: 0.4325 - val_Accuracy: 0.8531\n",
      "Epoch 6/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.4278 - Accuracy: 0.8545 - val_loss: 0.4006 - val_Accuracy: 0.8605\n",
      "Epoch 7/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.3873 - Accuracy: 0.8643 - val_loss: 0.3528 - val_Accuracy: 0.8714\n",
      "Epoch 8/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.3040 - Accuracy: 0.8883 - val_loss: 0.2591 - val_Accuracy: 0.9043\n",
      "Epoch 9/25\n",
      "2495/2495 [==============================] - 39s 16ms/step - loss: 0.2215 - Accuracy: 0.9169 - val_loss: 0.1713 - val_Accuracy: 0.9286\n",
      "Epoch 10/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.1316 - Accuracy: 0.9453 - val_loss: 0.0989 - val_Accuracy: 0.9579\n",
      "Epoch 11/25\n",
      "2495/2495 [==============================] - 41s 16ms/step - loss: 0.0810 - Accuracy: 0.9664 - val_loss: 0.0756 - val_Accuracy: 0.9692\n",
      "Epoch 12/25\n",
      "2495/2495 [==============================] - 39s 16ms/step - loss: 0.0516 - Accuracy: 0.9761 - val_loss: 0.0426 - val_Accuracy: 0.9785\n",
      "Epoch 13/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.0452 - Accuracy: 0.9775 - val_loss: 0.0395 - val_Accuracy: 0.9790\n",
      "Epoch 14/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.0367 - Accuracy: 0.9796 - val_loss: 0.0517 - val_Accuracy: 0.9750\n",
      "Epoch 15/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.0359 - Accuracy: 0.9802 - val_loss: 0.0334 - val_Accuracy: 0.9810\n",
      "Epoch 16/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.0326 - Accuracy: 0.9819 - val_loss: 0.0302 - val_Accuracy: 0.9837\n",
      "Epoch 17/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.0284 - Accuracy: 0.9844 - val_loss: 0.0271 - val_Accuracy: 0.9848\n",
      "Epoch 18/25\n",
      "2495/2495 [==============================] - 42s 17ms/step - loss: 0.0273 - Accuracy: 0.9850 - val_loss: 0.0259 - val_Accuracy: 0.9851\n",
      "Epoch 19/25\n",
      "2495/2495 [==============================] - 42s 17ms/step - loss: 0.0263 - Accuracy: 0.9851 - val_loss: 0.0263 - val_Accuracy: 0.9851\n",
      "Epoch 20/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.0254 - Accuracy: 0.9855 - val_loss: 0.0299 - val_Accuracy: 0.9844\n",
      "Epoch 21/25\n",
      "2495/2495 [==============================] - 39s 16ms/step - loss: 0.0252 - Accuracy: 0.9857 - val_loss: 0.0249 - val_Accuracy: 0.9856\n",
      "Epoch 22/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.0240 - Accuracy: 0.9861 - val_loss: 0.0250 - val_Accuracy: 0.9856\n",
      "Epoch 23/25\n",
      "2495/2495 [==============================] - 40s 16ms/step - loss: 0.0242 - Accuracy: 0.9864 - val_loss: 0.0244 - val_Accuracy: 0.9861\n",
      "Epoch 24/25\n",
      "2495/2495 [==============================] - 41s 17ms/step - loss: 0.0231 - Accuracy: 0.9865 - val_loss: 0.0249 - val_Accuracy: 0.9857\n",
      "Epoch 25/25\n",
      "2495/2495 [==============================] - 41s 16ms/step - loss: 0.0237 - Accuracy: 0.9865 - val_loss: 0.0237 - val_Accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d29503f2620>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['Accuracy'])\n",
    "\n",
    "model.fit(tmp_x[0], english_padded_text, verbose=1, batch_size=32, epochs=25, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "GRLOJSPZapSe"
   },
   "outputs": [],
   "source": [
    "model.save('language_translation_encdec.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxCmjcn156rJ",
    "outputId": "ed397dcf-eee1-4d32-f91d-9d4c11a0ad87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "      china is usually pleasant during november and it is never quiet in october  \n"
     ]
    }
   ],
   "source": [
    "def final_predictions():\n",
    "  sentence = 'chine est généralement agréable en novembre et il est jamais tranquille en octobre'\n",
    "  sentence = [french_tokenizer.word_index[word] for word in sentence.split()]\n",
    "  sentence = pad_sequences([sentence], maxlen=max_french_sequence_length, padding='post')\n",
    "  #print(french_tokenized_text[0])\n",
    "  sentences = numpy.array([sentence[0], french_padded_text[0]])\n",
    "  predictions = model.predict(sentences, len(sentences))\n",
    "  #print(predictions)\n",
    "  eng_id_to_word = {value: key for key, value in english_tokenizer.word_index.items()}\n",
    "  eng_id_to_word[0] = ''\n",
    "  print(' '.join([eng_id_to_word[numpy.argmax(value)] for value in predictions[0]]))\n",
    "  #print(eng_id_to_word)\n",
    "\n",
    "final_predictions()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
